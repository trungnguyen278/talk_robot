#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import asyncio
import wave
from datetime import datetime
from collections import deque
from pathlib import Path
from typing import Optional, List

import numpy as np
import soundfile as sf
import torch
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.responses import PlainTextResponse, JSONResponse

# =========================================================
# 1) ENV & PATCHES — ép in-process và tránh treo torchaudio
# =========================================================

def _patch_torchaudio_load():
    """Fallback torchaudio.load -> soundfile khi TorchCodec/FFmpeg lỗi."""
    try:
        import torchaudio, torch as _torch, numpy as _np, soundfile as _sf
        _orig = getattr(torchaudio, "load", None)
        if not callable(_orig):
            return
        def _safe_load(path, *args, **kwargs):
            try:
                return _orig(path, *args, **kwargs)
            except Exception:
                data, sr = _sf.read(path, dtype="float32", always_2d=True)  # (N,C)
                data = _torch.from_numpy(_np.ascontiguousarray(data.T))     # (C,N)
                return data, sr
        torchaudio.load = _safe_load
    except Exception:
        pass

# Backend chọn qua settings/modules: 1=F5, 2=ZipVoice
os.environ.setdefault("TTS_BACKEND", os.getenv("TTS_BACKEND", "2"))
# Ưu tiên native F5 (nạp model 1 lần) thay vì CLI
os.environ.setdefault("F5_NATIVE", os.getenv("F5_NATIVE", "1"))

# HF offline nếu đã có cache local
os.environ.setdefault("HF_HOME", "/home/devops/.cache/huggingface")
os.environ.setdefault("HUGGINGFACE_HUB_CACHE", os.path.join(os.environ["HF_HOME"], "hub"))
os.environ.setdefault("HF_HUB_OFFLINE", os.getenv("HF_HUB_OFFLINE", "1"))

# Tối ưu CPU threads để tránh tranh chấp
os.environ.setdefault("OMP_NUM_THREADS", "1")
os.environ.setdefault("MKL_NUM_THREADS", "1")

# Áp dụng patch torchaudio sớm
_patch_torchaudio_load()

# =========================================================
# 2) CẤU HÌNH AUDIO/VAD
# =========================================================
SAMPLE_RATE = 16000
BIT_DEPTH_BYTES = 2
CHANNELS = 1

# ESP32 gửi khối 1024 bytes (tương đương 512 mẫu int16 ~ 32ms @16k)
VAD_CHUNK_SIZE = 1024
VAD_SPEECH_THRESHOLD = 0.5
VAD_SILENCE_FRAMES_TRIGGER = 1
VAD_SILENCE_FRAMES_END = 50
VAD_BUFFER_FRAMES = 5

# =========================================================
# 3) IMPORT PIPELINE (nạp một lần) & SILERO VAD
# =========================================================
from modules.pipeline import VoiceAssistantPipeline

app = FastAPI()

_pipeline: Optional[VoiceAssistantPipeline] = None   # sẽ nạp ở startup
_vad_model = None
_vad_utils = None

def save_audio_to_wav(audio_data: bytes, folder: str = "audio_files") -> str:
    os.makedirs(folder, exist_ok=True)
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S_%f")
filename = os.path.join(folder, f"recording_{timestamp}.wav")
    # Ghi WAV 16k/mono/16bit
    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(BIT_DEPTH_BYTES)
        wf.setframerate(SAMPLE_RATE)
        wf.writeframes(audio_data)
    print(f"Audio saved: {filename}")
    return filename

async def _warmup_pipeline(pipeline: VoiceAssistantPipeline):
    """Gọi thử STT & TTS để warm-up model/vocoder cho lượt gọi đầu tiên nhanh hơn."""
    try:
        # Warm-up STT: 0.2s silence @16k
        silence = (np.zeros(int(0.2 * SAMPLE_RATE), dtype=np.float32) * 0).astype(np.float32)
        tmp_wav = Path("warmup_stt.wav")
        sf.write(str(tmp_wav), silence, SAMPLE_RATE)
        _ = await asyncio.to_thread(pipeline.stt_engine.transcribe, str(tmp_wav))
        try:
            tmp_wav.unlink(missing_ok=True)
        except Exception:
            pass
    except Exception as e:
        print(f"[Warmup] STT warmup failed (non-fatal): {e}")

    try:
        # Warm-up TTS: tạo 0.3s output để build graph/vocoder
        tmp_out = Path("warmup_tts.wav")
        _ = await asyncio.to_thread(pipeline.tts_engine.synthesize, "Xin chào.", str(tmp_out))
        try:
            tmp_out.unlink(missing_ok=True)
        except Exception:
            pass
    except Exception as e:
        print(f"[Warmup] TTS warmup failed (non-fatal): {e}")

@app.on_event("startup")
async def on_startup():
    global _pipeline, _vad_model, _vad_utils
    print("\n================= STARTUP =================")
    print(f"TTS_BACKEND={os.getenv('TTS_BACKEND')} (1=F5, 2=ZipVoice), F5_NATIVE={os.getenv('F5_NATIVE')}")
    try:
        # Nạp pipeline MỘT LẦN (STT/LLM/TTS đều nạp trong __init__)
        _pipeline = VoiceAssistantPipeline()
        print("✅ VoiceAssistantPipeline initialized.")

        # Warm-up để tránh chậm ở lượt đầu
        await _warmup_pipeline(_pipeline)
        print("✅ Warm-up done.")
    except Exception as e:
        print("❌ Pipeline init failed:")
        import traceback; traceback.print_exc()
        raise e

    # Nạp Silero VAD một lần
    try:
        torch.set_num_threads(1)
        _vad_model, _vad_utils = torch.hub.load(
            repo_or_dir='snakers4/silero-vad',
            model='silero_vad',
            force_reload=False,
            onnx=False
        )
        print("✅ Silero VAD model loaded.")
    except Exception as e:
        print(f"❌ Error loading Silero VAD: {e}")
        _vad_model, _vad_utils = None, None

@app.on_event("shutdown")
async def on_shutdown():
    print("Shutting down server...")

# =========================================================
# 4) ENDPOINTS “ESP-friendly”
# =========================================================

# Root trả về text thuần cho HTTPClient ESP32
@app.get("/", response_class=PlainTextResponse)
def root_plain():
    return "connect to ESP32"

# Health JSON (thay cho root JSON cũ)
@app.get("/health")
def health():
    return {
        "status": "Voice Assistant Server is running",
        "tts_backend": os.getenv("TTS_BACKEND"),
        "f5_native": os.getenv("F5_NATIVE"),
    }

# Ping đơn giản
@app.get("/ping", response_class=PlainTextResponse)
def ping():
    return "pong"

# POST /data — trả text “received” như ví dụ Flask
@app.post("/data", response_class=PlainTextResponse)
async def data(request: Request):
    # Bạn có thể đọc nội dung:
    # raw = await request.body()           # bytes
    # js = await request.json()            # khi Content-Type: application/json
    return "received"

# =========================================================
# 5) WEBSOCKET — dùng pipeline singleton đã nạp
# =========================================================
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    client = getattr(websocket, "client", None)
    print(f"Client connected: {getattr(client, 'host', 'unknown')}")

    if _pipeline is None:
        await websocket.close(code=1011, reason="Pipeline not initialized")
        return
    if _vad_model is None or _vad_utils is None:
        await websocket.close(code=1011, reason="VAD model not loaded")
        return

    get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks = _vad_utils

    is_speaking = False
    silence_counter = 0
    speech_trigger_counter = 0
    is_processing = False
    connection_closed = False

    pre_buffer = deque(maxlen=VAD_BUFFER_FRAMES)
    speech_buffer: List[bytes] = []

    try:
        while True:
            try:
                data = await websocket.receive_bytes()
            except WebSocketDisconnect:
                print("Client disconnected during receive.")
                return
            except RuntimeError as e:
                print(f"WebSocket runtime error during receive: {e}")
                return

            if is_processing:
                # Tạm bỏ qua frames trong lúc đang xử lý
                continue

            if len(data) != VAD_CHUNK_SIZE:
                # Bỏ qua chunk sai kích thước để VAD hoạt động ổn định
                continue

            # int16 -> float32 [-1..1]
            audio_numpy = np.frombuffer(data, dtype=np.int16).copy()
            audio_tensor = torch.from_numpy(audio_numpy).float() / 32768.0

            with torch.no_grad():
                speech_prob = _vad_model(audio_tensor, SAMPLE_RATE).item()

            if speech_prob > VAD_SPEECH_THRESHOLD:
                silence_counter = 0
                if not is_speaking:
                    speech_trigger_counter += 1
                    if speech_trigger_counter >= VAD_SILENCE_FRAMES_TRIGGER:
                        is_speaking = True
                        speech_buffer.extend(list(pre_buffer))
                if is_speaking:
                    speech_buffer.append(data)
            else:
                speech_trigger_counter = 0
if is_speaking:
                    silence_counter += 1
                    speech_buffer.append(data)
                    if silence_counter >= VAD_SILENCE_FRAMES_END:
                        # Kết thúc phát ngôn → xử lý pipeline
                        is_processing = True
                        await websocket.send_text("PROCESSING_START")

                        full_audio = b"".join(speech_buffer)
                        input_audio_path = save_audio_to_wav(full_audio)

                        if input_audio_path:
                            try:
                                # Gọi pipeline (đã nạp model in-process, không reload)
                                result = await asyncio.to_thread(
                                    _pipeline.process,
                                    audio_input_path=input_audio_path,
                                    session_id="ws-session",
                                )
                                output_audio_path = result.get("output_audio") if isinstance(result, dict) else None

                                if output_audio_path and os.path.exists(output_audio_path):
                                    # Stream WAV -> 16k mono int16 PCM chunks (ổn định cho client/ESP32)
                                    wav, sr = sf.read(str(output_audio_path), dtype='float32', always_2d=True)
                                    if wav.shape[1] > 1:
                                        wav = wav.mean(axis=1)
                                    else:
                                        wav = wav[:, 0]
                                    if sr != SAMPLE_RATE:
                                        new_len = int(len(wav) * SAMPLE_RATE / sr)
                                        wav = np.interp(
                                            np.linspace(0.0, 1.0, new_len, endpoint=False),
                                            np.linspace(0.0, 1.0, len(wav), endpoint=False),
                                            wav
                                        ).astype('float32')
                                        sr = SAMPLE_RATE

                                    wav = np.clip(wav, -1.0, 1.0)
                                    pcm_int16 = (wav * 32767.0).astype(np.int16)
                                    pcm_bytes = pcm_int16.tobytes()

                                    bytes_per_sample = 2
                                    samples_per_chunk = 512  # ~32ms @16kHz
                                    chunk_size = samples_per_chunk * bytes_per_sample
                                    chunk_dt = samples_per_chunk / float(SAMPLE_RATE)

                                    client_alive = True
                                    for i in range(0, len(pcm_bytes), chunk_size):
                                        chunk = pcm_bytes[i:i+chunk_size]
                                        if not chunk or not client_alive:
break
                                        try:
                                            await websocket.send_bytes(chunk)
                                        except Exception:
                                            client_alive = False
                                            connection_closed = True
                                            break
                                        await asyncio.sleep(chunk_dt)
                                else:
                                    print("Pipeline did not return a valid audio path.")
                            except Exception as e:
                                print(f"Pipeline processing error: {e}")
                            finally:
                                try:
                                    await websocket.send_text("TTS_END")
                                except Exception:
                                    pass
                                if connection_closed:
                                    return

                        # Reset VAD state
                        is_speaking = False
                        silence_counter = 0
                        speech_buffer.clear()
                        pre_buffer.clear()
                        is_processing = False
                else:
                    pre_buffer.append(data)

    except WebSocketDisconnect:
        print("Client disconnected.")
    except Exception:
        import traceback; traceback.print_exc()
