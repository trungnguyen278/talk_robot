"""
Text-to-Speech Module with In-Memory Model Caching and CUDA Acceleration
Model: ZipVoice
"""
import sys
import json
from pathlib import Path
import torch
import soundfile as sf
from settings import tts_settings as cfg
import traceback

# === [GI·∫¢I PH√ÅP] Th√™m ƒë∆∞·ªùng d·∫´n m√£ ngu·ªìn ZipVoice v√†o sys.path ===
# ƒêi·ªÅu n√†y gi·∫£i quy·∫øt tri·ªát ƒë·ªÉ l·ªói "ModuleNotFoundError: No module named 'zipvoice'".
if str(cfg.ZIPVOICE_CODE_DIR) not in sys.path:
    sys.path.insert(0, str(cfg.ZIPVOICE_CODE_DIR))
# =================================================================

# === [B∆Ø·ªöC 1] IMPORT T·∫§T C·∫¢ C√ÅC TH√ÄNH PH·∫¶N C·∫¶N THI·∫æT ===
try:
    # Model ch√≠nh v√† Vocoder
    from zipvoice.models.zipvoice import ZipVoice
    from vocos import Vocos

    # Tokenizer
    from zipvoice.tokenizer.tokenizer import EspeakTokenizer

    # C√°c h√†m ti·ªán √≠ch
    from zipvoice.utils.checkpoint import load_checkpoint
    from zipvoice.utils.feature import VocosFbank
    # [ƒê√É S·ª¨A L·ªñI] S·ª≠a t√™n file import t·ª´ 'infer_utils' th√†nh 'infer'
    from zipvoice.utils.infer import (
        add_punctuation,
        chunk_tokens_punctuation,
        cross_fade_concat,
        load_prompt_wav,
        remove_silence,
        rms_norm,
    )
except ImportError as e:
    print(" L·ªñI IMPORT NGHI√äM TR·ªåNG ".center(80, "!"))
    print(f"Kh√¥ng th·ªÉ import c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt. L·ªói: {e}")
    print("Vui l√≤ng ki·ªÉm tra c√°c ƒëi·ªÅu sau:")
    print(f"1. Th∆∞ m·ª•c '{cfg.ZIPVOICE_CODE_DIR}' c√≥ t·ªìn t·∫°i.")
    print(f"2. B·∫°n ƒë√£ c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán ch∆∞a? Ch·∫°y l·ªánh: pip install vocos k2")
    sys.exit(1)


class TTSEngine:
    def __init__(self):
        self._validate_setup()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"‚úÖ TTS Engine s·∫Ω ch·∫°y tr√™n thi·∫øt b·ªã: {self.device}.")

        print("üîß ƒêang t·∫£i t·∫•t c·∫£ c√°c model TTS v√†o b·ªô nh·ªõ (ch·ªâ m·ªôt l·∫ßn)...")
        
        try:
            # --- 1. T·∫£i c·∫•u h√¨nh t·ª´ model.json ---
            model_config_path = cfg.MODEL_DIR / "model.json"
            if not model_config_path.exists():
                raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file c·∫•u h√¨nh model t·∫°i: {model_config_path}")
            with open(model_config_path, "r") as f:
                self.model_config = json.load(f)
            self.sampling_rate = self.model_config["feature"]["sampling_rate"]
            print(f"  ‚úì ƒê√£ t·∫£i c·∫•u h√¨nh, sample rate l√† {self.sampling_rate} Hz.")

            # --- 2. Kh·ªüi t·∫°o Tokenizer ---
            token_file = cfg.MODEL_DIR / "tokens.txt"
            if not token_file.exists():
                raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file tokens t·∫°i: {token_file}")
            self.tokenizer = EspeakTokenizer(token_file=token_file, lang=cfg.LANG)
            tokenizer_config = {"vocab_size": self.tokenizer.vocab_size, "pad_id": self.tokenizer.pad_id}
            print("  ‚úì Tokenizer ƒë√£ s·∫µn s√†ng.")

            # --- 3. Kh·ªüi t·∫°o Model ch√≠nh (ZipVoice) ---
            self.model = ZipVoice(**self.model_config["model"], **tokenizer_config)
            checkpoint_path = self._find_checkpoint()
            load_checkpoint(filename=str(checkpoint_path), model=self.model, strict=True)
            self.model.to(self.device)
            self.model.eval()
            print("  ‚úì Model ZipVoice ch√≠nh ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n GPU.")

            # --- 4. Kh·ªüi t·∫°o Vocoder ---
            self.vocoder = Vocos.from_pretrained("charactr/vocos-mel-24khz")
            self.vocoder.to(self.device)
            self.vocoder.eval()
            print("  ‚úì Vocoder ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n GPU.")

            # --- 5. Kh·ªüi t·∫°o Feature Extractor ---
            self.feature_extractor = VocosFbank()
            print("  ‚úì Feature Extractor ƒë√£ s·∫µn s√†ng.")

            print("‚úÖ T·∫•t c·∫£ c√°c th√†nh ph·∫ßn TTS ƒë√£ s·∫µn s√†ng!")

        except Exception as e:
            print(" L·ªñI KH·ªûI T·∫†O MODEL TTS ".center(80, "‚ùå"))
            traceback.print_exc()
            raise

        cfg.OUTPUT_AUDIO_DIR.mkdir(parents=True, exist_ok=True)

    def _validate_setup(self):
        if not cfg.ZIPVOICE_CODE_DIR.exists():
            raise FileNotFoundError(f"Th∆∞ m·ª•c m√£ ngu·ªìn ZipVoice kh√¥ng t√¨m th·∫•y: {cfg.ZIPVOICE_CODE_DIR}")
        if not cfg.MODEL_DIR.exists():
            raise FileNotFoundError(f"Th∆∞ m·ª•c model ZipVoice kh√¥ng t√¨m th·∫•y: {cfg.MODEL_DIR}")

    def _find_checkpoint(self) -> Path:
        for ext in cfg.CHECKPOINT_EXTENSIONS:
            files = list(cfg.MODEL_DIR.glob(f"*{ext}"))
            if files:
                return files[0]
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file checkpoint trong '{cfg.MODEL_DIR}'")

    @torch.inference_mode()
    def synthesize(self, text: str, output_path: str = None, ref_audio: str = None, prompt_text: str = None) -> Path:
        output_wav_path = Path(output_path) if output_path else cfg.OUTPUT_AUDIO_DIR / "output.wav"
        ref_audio_path = ref_audio or cfg.DEFAULT_REF_AUDIO
        prompt_text = prompt_text or cfg.DEFAULT_PROMPT_TEXT
        
        print(f"üîä ƒêang t·ªïng h·ª£p gi·ªçng n√≥i tr√™n '{self.device}': '{text[:40]}...'")

        # --- 1. Chu·∫©n b·ªã Audio Prompt ---
        prompt_wav = load_prompt_wav(str(ref_audio_path), sampling_rate=self.sampling_rate)
        prompt_wav = remove_silence(prompt_wav, self.sampling_rate, only_edge=False, trail_sil=200)
        prompt_wav, prompt_rms = rms_norm(prompt_wav, target_rms=0.1)
        prompt_features = self.feature_extractor.extract(prompt_wav, sampling_rate=self.sampling_rate).to(self.device)
        prompt_features = prompt_features.unsqueeze(0) * 0.1 # feat_scale

        # --- 2. Chu·∫©n b·ªã Text ---
        text = add_punctuation(text)
        prompt_text = add_punctuation(prompt_text)
        tokens_str = self.tokenizer.texts_to_tokens([text])[0]
        prompt_tokens_str = self.tokenizer.texts_to_tokens([prompt_text])[0]
        prompt_tokens = self.tokenizer.tokens_to_token_ids([prompt_tokens_str])
        
        # Chia text th√†nh c√°c ƒëo·∫°n nh·ªè ƒë·ªÉ tr√°nh OOM v√† c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng
        chunked_tokens_str = chunk_tokens_punctuation(tokens_str, max_tokens=100)
        chunked_tokens = self.tokenizer.tokens_to_token_ids(chunked_tokens_str)
        
        # --- 3. T·ªïng h·ª£p ƒë·∫∑c tr∆∞ng √¢m thanh (acoustic features) ---
        wav_chunks = []
        for tokens_chunk in chunked_tokens:
            batch_tokens = [tokens_chunk]
            batch_prompt_tokens = prompt_tokens * len(batch_tokens)
            batch_prompt_features = prompt_features.repeat(len(batch_tokens), 1, 1)
            batch_prompt_features_lens = torch.full((len(batch_tokens),), prompt_features.size(1), device=self.device)
            
            pred_features, _, _, _ = self.model.sample(
                tokens=batch_tokens,
                prompt_tokens=batch_prompt_tokens,
                prompt_features=batch_prompt_features,
                prompt_features_lens=batch_prompt_features_lens,
                speed=cfg.SPEECH_SPEED,
                num_step=cfg.NUM_STEP,
                guidance_scale=3.0 # Gi√° tr·ªã m·∫∑c ƒë·ªãnh t·ªët cho model n√†y
            )
            pred_features = pred_features.permute(0, 2, 1) / 0.1 # feat_scale
            
            # --- 4. D√πng Vocoder ƒë·ªÉ chuy·ªÉn features th√†nh audio ---
            for i in range(pred_features.size(0)):
                wav = self.vocoder.decode(pred_features[i].unsqueeze(0)).squeeze(1).clamp(-1, 1)
                if prompt_rms < 0.1:
                    wav = wav * prompt_rms / 0.1
                wav_chunks.append(wav)
        
        # --- 5. N·ªëi c√°c ƒëo·∫°n audio v√† l∆∞u file ---
        final_wav = cross_fade_concat(wav_chunks, fade_duration=0.1, sample_rate=self.sampling_rate)
        final_wav = remove_silence(final_wav, self.sampling_rate, only_edge=(not cfg.REMOVE_LONG_SIL))
        
        sf.write(str(output_wav_path), final_wav.cpu().squeeze().numpy(), self.sampling_rate)
        
        print(f"‚úÖ File √¢m thanh ƒë√£ ƒë∆∞·ª£c t·∫°o: {output_wav_path}")
        return output_wav_path


if __name__ == '__main__':
    print("\n" + "="*80)
    print(" CH·∫†Y TH·ª¨ NGHI·ªÜM MODULE TTS ".center(80))
    print("="*80 + "\n")
    try:
        engine = TTSEngine()
        print("\n--> KI·ªÇM TRA `nvidia-smi` NGAY! B·∫°n s·∫Ω th·∫•y b·ªô nh·ªõ VRAM ƒë∆∞·ª£c s·ª≠ d·ª•ng. <--\n")
        
        path1 = engine.synthesize("Xin ch√†o, ƒë√¢y l√† phi√™n b·∫£n ƒë√£ s·ª≠a l·ªói ho√†n ch·ªânh.")
        print(f"--> K·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u t·∫°i: {path1}")
        
        print("\n" + "‚úÖ CH·∫†Y TH·ª¨ NGHI·ªÜM TH√ÄNH C√îNG! ".center(80, "=") + "\n")

    except Exception as e:
        print(f"\nL·ªñI trong qu√° tr√¨nh ch·∫°y th·ª≠ nghi·ªám: {e}")
        traceback.print_exc()